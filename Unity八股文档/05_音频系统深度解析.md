# Unity音频系统深度解析

## 目录
1. [音频系统架构](#音频系统架构)
2. [AudioSource详解](#audiosource详解)
3. [AudioMixer系统](#audiomixer系统)
4. [3D音频和空间化](#3d音频和空间化)
5. [音频优化策略](#音频优化策略)
6. [常见面试问题](#常见面试问题)

---

## 音频系统架构

### Unity音频系统概述
```
Unity Audio System
├── AudioListener (音频监听器)
│   ├── 场景中只能有一个激活的AudioListener
│   ├── 通常附加到主相机或玩家
│   └── 负责接收和处理音频信号
├── AudioSource (音频源)
│   ├── 播放AudioClip
│   ├── 控制音量、音调、3D设置
│   └── 支持多种播放模式
├── AudioClip (音频剪辑)
│   ├── 音频数据容器
│   ├── 支持多种音频格式
│   └── 可配置压缩和加载方式
└── AudioMixer (音频混合器)
    ├── 高级音频处理
    ├── 实时音效和滤波
    └── 动态混音控制
```

### 音频引擎底层架构
```csharp
public class AudioSystemArchitecture
{
    // Unity音频系统的底层组件
    /*
    音频渲染流程：
    1. AudioClip → 音频数据源
    2. AudioSource → 音频播放控制
    3. AudioMixerGroup → 音频处理和混合
    4. AudioListener → 音频接收和输出
    5. Platform Audio Driver → 硬件音频输出
    */
    
    void ExplainAudioPipeline()
    {
        /*
        音频处理管线：
        
        [AudioClip] 
            ↓ (Load/Stream)
        [AudioSource] 
            ↓ (Volume/Pitch/3D Processing)
        [AudioMixerGroup] 
            ↓ (Effects/Filtering)
        [Master Mix] 
            ↓ (Final Processing)
        [AudioListener] 
            ↓ (Spatialization)
        [Hardware Output]
        */
    }
    
    // 音频线程模型
    void AudioThreadModel()
    {
        /*
        Unity音频系统采用多线程架构：
        
        Main Thread:
        - AudioSource控制
        - AudioMixer参数设置
        - 脚本API调用
        
        Audio Thread:
        - 音频数据处理
        - 效果器计算
        - 混音处理
        
        Streaming Thread:
        - 音频文件加载
        - 压缩数据解码
        */
    }
}
```

---

## AudioSource详解

### AudioSource核心属性

#### 1. 基本播放控制
```csharp
public class AudioSourceController : MonoBehaviour
{
    private AudioSource audioSource;
    
    [Header("基本设置")]
    public AudioClip audioClip;
    public bool playOnAwake = false;
    public bool loop = false;
    
    [Header("音量和音调")]
    [Range(0f, 1f)]
    public float volume = 1f;
    [Range(-3f, 3f)]
    public float pitch = 1f;
    
    [Header("优先级")]
    [Range(0, 256)]
    public int priority = 128;
    
    void Start()
    {
        audioSource = GetComponent<AudioSource>();
        SetupAudioSource();
    }
    
    void SetupAudioSource()
    {
        // 基本设置
        audioSource.clip = audioClip;
        audioSource.playOnAwake = playOnAwake;
        audioSource.loop = loop;
        audioSource.volume = volume;
        audioSource.pitch = pitch;
        audioSource.priority = priority;
        
        // 详细配置
        ConfigureAdvancedSettings();
    }
    
    void ConfigureAdvancedSettings()
    {
        // 立体声平移
        audioSource.panStereo = 0f; // -1(左) 到 1(右)
        
        // 空间混合
        audioSource.spatialBlend = 0f; // 0=2D, 1=3D
        
        // 多普勒效果
        audioSource.dopplerLevel = 1f;
        
        // 回响区域混合
        audioSource.reverbZoneMix = 1f;
    }
    
    // 播放控制方法
    public void PlayAudio()
    {
        if (audioSource && audioClip)
        {
            audioSource.Play();
        }
    }
    
    public void PlayOneShot(AudioClip clip, float volumeScale = 1f)
    {
        if (audioSource && clip)
        {
            audioSource.PlayOneShot(clip, volumeScale);
        }
    }
    
    public void PlayDelayed(float delay)
    {
        if (audioSource && audioClip)
        {
            audioSource.PlayDelayed(delay);
        }
    }
    
    public void PlayScheduled(double time)
    {
        if (audioSource && audioClip)
        {
            audioSource.PlayScheduled(time);
        }
    }
    
    public void StopAudio()
    {
        if (audioSource)
        {
            audioSource.Stop();
        }
    }
    
    public void PauseAudio()
    {
        if (audioSource)
        {
            audioSource.Pause();
        }
    }
    
    public void UnPauseAudio()
    {
        if (audioSource)
        {
            audioSource.UnPause();
        }
    }
    
    // 音频状态检测
    public bool IsPlaying()
    {
        return audioSource && audioSource.isPlaying;
    }
    
    public float GetPlaybackTime()
    {
        return audioSource ? audioSource.time : 0f;
    }
    
    public int GetPlaybackTimeSamples()
    {
        return audioSource ? audioSource.timeSamples : 0;
    }
}
```

#### 2. 3D音频设置
```csharp
public class Audio3DController : MonoBehaviour
{
    private AudioSource audioSource;
    
    [Header("3D音频设置")]
    public AudioRolloffMode rolloffMode = AudioRolloffMode.Logarithmic;
    public float minDistance = 1f;
    public float maxDistance = 500f;
    
    [Header("3D音频曲线")]
    public AnimationCurve volumeRolloffCurve = AnimationCurve.Linear(0, 1, 1, 0);
    public AnimationCurve spatialBlendCurve = AnimationCurve.Linear(0, 0, 1, 1);
    public AnimationCurve reverbZoneMixCurve = AnimationCurve.Linear(0, 1, 1, 1);
    public AnimationCurve spreadCurve = AnimationCurve.Linear(0, 0, 1, 0);
    
    void Start()
    {
        audioSource = GetComponent<AudioSource>();
        Setup3DAudio();
    }
    
    void Setup3DAudio()
    {
        // 启用3D音频
        audioSource.spatialBlend = 1f; // 完全3D
        
        // 设置距离衰减
        audioSource.rolloffMode = rolloffMode;
        audioSource.minDistance = minDistance;
        audioSource.maxDistance = maxDistance;
        
        // 设置自定义曲线
        if (rolloffMode == AudioRolloffMode.Custom)
        {
            audioSource.SetCustomCurve(AudioSourceCurveType.CustomRolloff, volumeRolloffCurve);
        }
        
        audioSource.SetCustomCurve(AudioSourceCurveType.SpatialBlend, spatialBlendCurve);
        audioSource.SetCustomCurve(AudioSourceCurveType.ReverbZoneMix, reverbZoneMixCurve);
        audioSource.SetCustomCurve(AudioSourceCurveType.Spread, spreadCurve);
        
        // 多普勒设置
        SetupDopplerEffect();
    }
    
    void SetupDopplerEffect()
    {
        // 多普勒效应设置
        audioSource.dopplerLevel = 1f;
        
        // 全局多普勒设置
        AudioSettings.dopplerFactor = 1f;
        AudioSettings.speedOfSound = 343f; // 声速 m/s
    }
    
    // 距离衰减计算
    float CalculateVolumeByDistance(float distance)
    {
        switch (rolloffMode)
        {
            case AudioRolloffMode.Logarithmic:
                return CalculateLogarithmicRolloff(distance);
                
            case AudioRolloffMode.Linear:
                return CalculateLinearRolloff(distance);
                
            case AudioRolloffMode.Custom:
                return volumeRolloffCurve.Evaluate(distance / maxDistance);
                
            default:
                return 1f;
        }
    }
    
    float CalculateLogarithmicRolloff(float distance)
    {
        if (distance <= minDistance)
            return 1f;
        
        if (distance >= maxDistance)
            return 0f;
        
        return minDistance / distance;
    }
    
    float CalculateLinearRolloff(float distance)
    {
        if (distance <= minDistance)
            return 1f;
        
        if (distance >= maxDistance)
            return 0f;
        
        return 1f - (distance - minDistance) / (maxDistance - minDistance);
    }
    
    // 运行时调试
    void Update()
    {
        if (Application.isEditor)
        {
            DebugAudio3D();
        }
    }
    
    void DebugAudio3D()
    {
        if (audioSource.isPlaying)
        {
            float distanceToListener = Vector3.Distance(transform.position, 
                AudioListener.transform.position);
            
            float calculatedVolume = CalculateVolumeByDistance(distanceToListener);
            
            Debug.Log($"Distance: {distanceToListener:F2}m, Volume: {calculatedVolume:F2}");
        }
    }
    
    void OnDrawGizmosSelected()
    {
        // 绘制音频范围
        Gizmos.color = Color.yellow;
        Gizmos.DrawWireSphere(transform.position, minDistance);
        
        Gizmos.color = Color.red;
        Gizmos.DrawWireSphere(transform.position, maxDistance);
    }
}
```

#### 3. 音频流和压缩
```csharp
public class AudioCompressionController : MonoBehaviour
{
    [Header("音频压缩设置")]
    public AudioClipLoadType loadType = AudioClipLoadType.DecompressOnLoad;
    public AudioCompressionFormat compressionFormat = AudioCompressionFormat.Vorbis;
    public float quality = 0.5f;
    
    void Start()
    {
        ExplainAudioCompression();
    }
    
    void ExplainAudioCompression()
    {
        /*
        AudioClipLoadType类型：
        
        1. DecompressOnLoad：
           - 加载时解压到内存
           - 播放时CPU开销最小
           - 内存占用最大
           - 适合：短音效、频繁播放的音频
        
        2. CompressedInMemory：
           - 保持压缩状态在内存中
           - 播放时实时解压
           - 平衡内存和CPU
           - 适合：中等长度音频
        
        3. Streaming：
           - 从磁盘流式加载
           - 内存占用最小
           - 磁盘I/O开销
           - 适合：背景音乐、长音频
        */
        
        Debug.Log($"Current load type: {loadType}");
        Debug.Log($"Compression format: {compressionFormat}");
    }
    
    // 运行时音频加载
    public IEnumerator LoadAudioClip(string path, AudioClipLoadType loadType)
    {
        using (UnityWebRequest www = UnityWebRequestMultimedia.GetAudioClip(path, AudioType.MPEG))
        {
            // 设置下载处理器
            DownloadHandlerAudioClip downloadHandler = (DownloadHandlerAudioClip)www.downloadHandler;
            downloadHandler.compressed = (loadType == AudioClipLoadType.CompressedInMemory);
            downloadHandler.streamAudio = (loadType == AudioClipLoadType.Streaming);
            
            yield return www.SendWebRequest();
            
            if (www.result == UnityWebRequest.Result.Success)
            {
                AudioClip clip = downloadHandler.audioClip;
                clip.LoadAudioData(); // 确保音频数据已加载
                
                GetComponent<AudioSource>().clip = clip;
            }
            else
            {
                Debug.LogError($"Failed to load audio: {www.error}");
            }
        }
    }
    
    // 音频内存管理
    void ManageAudioMemory()
    {
        AudioClip clip = GetComponent<AudioSource>().clip;
        
        if (clip != null)
        {
            // 检查加载状态
            Debug.Log($"Load state: {clip.loadState}");
            Debug.Log($"Load in background: {clip.loadInBackground}");
            
            // 手动加载/卸载
            if (clip.loadState == AudioDataLoadState.Unloaded)
            {
                clip.LoadAudioData();
            }
            
            // 卸载音频数据（保留引用）
            if (clip.loadState == AudioDataLoadState.Loaded)
            {
                clip.UnloadAudioData();
            }
        }
    }
}
```

---

## AudioMixer系统

### AudioMixer架构和使用

#### 1. AudioMixer基础设置
```csharp
public class AudioMixerController : MonoBehaviour
{
    [Header("AudioMixer设置")]
    public AudioMixer audioMixer;
    public AudioMixerGroup masterGroup;
    public AudioMixerGroup musicGroup;
    public AudioMixerGroup sfxGroup;
    public AudioMixerGroup voiceGroup;
    
    [Header("音量控制")]
    [Range(-80f, 20f)]
    public float masterVolume = 0f;
    [Range(-80f, 20f)]
    public float musicVolume = 0f;
    [Range(-80f, 20f)]
    public float sfxVolume = 0f;
    [Range(-80f, 20f)]
    public float voiceVolume = 0f;
    
    // 参数名称常量
    private const string MASTER_VOLUME = "MasterVolume";
    private const string MUSIC_VOLUME = "MusicVolume";
    private const string SFX_VOLUME = "SFXVolume";
    private const string VOICE_VOLUME = "VoiceVolume";
    
    void Start()
    {
        InitializeAudioMixer();
        LoadAudioSettings();
    }
    
    void InitializeAudioMixer()
    {
        if (audioMixer == null)
        {
            Debug.LogError("AudioMixer not assigned!");
            return;
        }
        
        // 设置初始音量
        SetMasterVolume(masterVolume);
        SetMusicVolume(musicVolume);
        SetSFXVolume(sfxVolume);
        SetVoiceVolume(voiceVolume);
    }
    
    // 音量控制方法
    public void SetMasterVolume(float volume)
    {
        audioMixer.SetFloat(MASTER_VOLUME, volume);
        masterVolume = volume;
    }
    
    public void SetMusicVolume(float volume)
    {
        audioMixer.SetFloat(MUSIC_VOLUME, volume);
        musicVolume = volume;
    }
    
    public void SetSFXVolume(float volume)
    {
        audioMixer.SetFloat(SFX_VOLUME, volume);
        sfxVolume = volume;
    }
    
    public void SetVoiceVolume(float volume)
    {
        audioMixer.SetFloat(VOICE_VOLUME, volume);
        voiceVolume = volume;
    }
    
    // 获取音量值
    public float GetMasterVolume()
    {
        audioMixer.GetFloat(MASTER_VOLUME, out float volume);
        return volume;
    }
    
    public float GetMusicVolume()
    {
        audioMixer.GetFloat(MUSIC_VOLUME, out float volume);
        return volume;
    }
    
    // 音量平滑过渡
    public void SetMasterVolumeSmooth(float targetVolume, float duration)
    {
        StartCoroutine(SmoothVolumeTransition(MASTER_VOLUME, targetVolume, duration));
    }
    
    IEnumerator SmoothVolumeTransition(string parameterName, float targetVolume, float duration)
    {
        audioMixer.GetFloat(parameterName, out float currentVolume);
        
        float elapsedTime = 0f;
        
        while (elapsedTime < duration)
        {
            elapsedTime += Time.deltaTime;
            float t = elapsedTime / duration;
            
            float volume = Mathf.Lerp(currentVolume, targetVolume, t);
            audioMixer.SetFloat(parameterName, volume);
            
            yield return null;
        }
        
        audioMixer.SetFloat(parameterName, targetVolume);
    }
    
    // 保存和加载音频设置
    void SaveAudioSettings()
    {
        PlayerPrefs.SetFloat("MasterVolume", masterVolume);
        PlayerPrefs.SetFloat("MusicVolume", musicVolume);
        PlayerPrefs.SetFloat("SFXVolume", sfxVolume);
        PlayerPrefs.SetFloat("VoiceVolume", voiceVolume);
    }
    
    void LoadAudioSettings()
    {
        if (PlayerPrefs.HasKey("MasterVolume"))
        {
            SetMasterVolume(PlayerPrefs.GetFloat("MasterVolume"));
            SetMusicVolume(PlayerPrefs.GetFloat("MusicVolume"));
            SetSFXVolume(PlayerPrefs.GetFloat("SFXVolume"));
            SetVoiceVolume(PlayerPrefs.GetFloat("VoiceVolume"));
        }
    }
    
    void OnApplicationPause(bool pauseStatus)
    {
        if (pauseStatus)
        {
            SaveAudioSettings();
        }
    }
    
    void OnApplicationFocus(bool hasFocus)
    {
        if (!hasFocus)
        {
            SaveAudioSettings();
        }
    }
}
```

#### 2. AudioMixer效果器控制
```csharp
public class AudioMixerEffectsController : MonoBehaviour
{
    [Header("音频效果器")]
    public AudioMixer audioMixer;
    
    [Header("低通滤波器")]
    [Range(10f, 22000f)]
    public float lowpassCutoff = 22000f;
    [Range(1f, 10f)]
    public float lowpassResonance = 1f;
    
    [Header("高通滤波器")]
    [Range(10f, 22000f)]
    public float highpassCutoff = 10f;
    [Range(1f, 10f)]
    public float highpassResonance = 1f;
    
    [Header("回响效果")]
    [Range(-10000f, 1000f)]
    public float reverbRoom = -1000f;
    [Range(0f, 20f)]
    public float reverbDecayTime = 1.49f;
    [Range(0.1f, 2f)]
    public float reverbDecayHFRatio = 0.83f;
    
    [Header("失真效果")]
    [Range(0f, 1f)]
    public float distortionLevel = 0.5f;
    
    [Header("合唱效果")]
    [Range(0f, 1f)]
    public float chorusRate = 0.8f;
    [Range(0f, 1f)]
    public float chorusDepth = 0.03f;
    
    void Start()
    {
        ApplyAudioEffects();
    }
    
    void ApplyAudioEffects()
    {
        // 低通滤波器
        audioMixer.SetFloat("LowpassCutoff", lowpassCutoff);
        audioMixer.SetFloat("LowpassResonance", lowpassResonance);
        
        // 高通滤波器
        audioMixer.SetFloat("HighpassCutoff", highpassCutoff);
        audioMixer.SetFloat("HighpassResonance", highpassResonance);
        
        // 回响效果
        audioMixer.SetFloat("ReverbRoom", reverbRoom);
        audioMixer.SetFloat("ReverbDecayTime", reverbDecayTime);
        audioMixer.SetFloat("ReverbDecayHFRatio", reverbDecayHFRatio);
        
        // 失真效果
        audioMixer.SetFloat("DistortionLevel", distortionLevel);
        
        // 合唱效果
        audioMixer.SetFloat("ChorusRate", chorusRate);
        audioMixer.SetFloat("ChorusDepth", chorusDepth);
    }
    
    // 动态音频效果
    public void ApplyUnderwaterEffect()
    {
        StartCoroutine(TransitionToUnderwaterEffect());
    }
    
    IEnumerator TransitionToUnderwaterEffect()
    {
        float duration = 1f;
        float elapsedTime = 0f;
        
        // 目标值
        float targetLowpass = 1000f;
        float targetReverb = -500f;
        
        // 起始值
        audioMixer.GetFloat("LowpassCutoff", out float startLowpass);
        audioMixer.GetFloat("ReverbRoom", out float startReverb);
        
        while (elapsedTime < duration)
        {
            elapsedTime += Time.deltaTime;
            float t = elapsedTime / duration;
            
            float currentLowpass = Mathf.Lerp(startLowpass, targetLowpass, t);
            float currentReverb = Mathf.Lerp(startReverb, targetReverb, t);
            
            audioMixer.SetFloat("LowpassCutoff", currentLowpass);
            audioMixer.SetFloat("ReverbRoom", currentReverb);
            
            yield return null;
        }
    }
    
    public void RemoveUnderwaterEffect()
    {
        StartCoroutine(TransitionFromUnderwaterEffect());
    }
    
    IEnumerator TransitionFromUnderwaterEffect()
    {
        float duration = 1f;
        float elapsedTime = 0f;
        
        // 恢复正常值
        float targetLowpass = 22000f;
        float targetReverb = -1000f;
        
        audioMixer.GetFloat("LowpassCutoff", out float startLowpass);
        audioMixer.GetFloat("ReverbRoom", out float startReverb);
        
        while (elapsedTime < duration)
        {
            elapsedTime += Time.deltaTime;
            float t = elapsedTime / duration;
            
            float currentLowpass = Mathf.Lerp(startLowpass, targetLowpass, t);
            float currentReverb = Mathf.Lerp(startReverb, targetReverb, t);
            
            audioMixer.SetFloat("LowpassCutoff", currentLowpass);
            audioMixer.SetFloat("ReverbRoom", currentReverb);
            
            yield return null;
        }
    }
    
    // 预设效果器配置
    public void ApplyPreset(AudioEffectPreset preset)
    {
        switch (preset)
        {
            case AudioEffectPreset.Normal:
                ApplyNormalPreset();
                break;
            case AudioEffectPreset.Cave:
                ApplyCavePreset();
                break;
            case AudioEffectPreset.Underwater:
                ApplyUnderwaterPreset();
                break;
            case AudioEffectPreset.Arena:
                ApplyArenaPreset();
                break;
        }
    }
    
    void ApplyNormalPreset()
    {
        audioMixer.SetFloat("LowpassCutoff", 22000f);
        audioMixer.SetFloat("ReverbRoom", -1000f);
        audioMixer.SetFloat("ReverbDecayTime", 1.49f);
    }
    
    void ApplyCavePreset()
    {
        audioMixer.SetFloat("LowpassCutoff", 5000f);
        audioMixer.SetFloat("ReverbRoom", -200f);
        audioMixer.SetFloat("ReverbDecayTime", 2.91f);
        audioMixer.SetFloat("ReverbDecayHFRatio", 1.30f);
    }
    
    void ApplyUnderwaterPreset()
    {
        audioMixer.SetFloat("LowpassCutoff", 1000f);
        audioMixer.SetFloat("ReverbRoom", -500f);
        audioMixer.SetFloat("ReverbDecayTime", 1.84f);
    }
    
    void ApplyArenaPreset()
    {
        audioMixer.SetFloat("ReverbRoom", -100f);
        audioMixer.SetFloat("ReverbDecayTime", 4.32f);
        audioMixer.SetFloat("ReverbDecayHFRatio", 0.59f);
    }
}

public enum AudioEffectPreset
{
    Normal,
    Cave,
    Underwater,
    Arena
}
```

#### 3. AudioMixer快照系统
```csharp
public class AudioMixerSnapshotController : MonoBehaviour
{
    [Header("音频快照")]
    public AudioMixer audioMixer;
    public AudioMixerSnapshot normalSnapshot;
    public AudioMixerSnapshot pausedSnapshot;
    public AudioMixerSnapshot combatSnapshot;
    public AudioMixerSnapshot menuSnapshot;
    
    [Header("过渡设置")]
    public float transitionTime = 1f;
    
    private AudioMixerSnapshot currentSnapshot;
    
    void Start()
    {
        if (normalSnapshot != null)
        {
            currentSnapshot = normalSnapshot;
            normalSnapshot.TransitionTo(0f);
        }
    }
    
    // 快照切换方法
    public void TransitionToSnapshot(GameState gameState)
    {
        AudioMixerSnapshot targetSnapshot = null;
        
        switch (gameState)
        {
            case GameState.Normal:
                targetSnapshot = normalSnapshot;
                break;
            case GameState.Paused:
                targetSnapshot = pausedSnapshot;
                break;
            case GameState.Combat:
                targetSnapshot = combatSnapshot;
                break;
            case GameState.Menu:
                targetSnapshot = menuSnapshot;
                break;
        }
        
        if (targetSnapshot != null && targetSnapshot != currentSnapshot)
        {
            targetSnapshot.TransitionTo(transitionTime);
            currentSnapshot = targetSnapshot;
        }
    }
    
    // 混合快照过渡
    public void TransitionToBlendedSnapshot(AudioMixerSnapshot[] snapshots, float[] weights)
    {
        if (snapshots.Length != weights.Length)
        {
            Debug.LogError("Snapshots and weights arrays must have the same length");
            return;
        }
        
        audioMixer.TransitionToSnapshots(snapshots, weights, transitionTime);
    }
    
    // 自定义快照混合
    public void CreateDynamicSnapshot(float musicWeight, float sfxWeight, float voiceWeight)
    {
        AudioMixerSnapshot[] snapshots = { normalSnapshot, combatSnapshot };
        float[] weights = { musicWeight, 1f - musicWeight };
        
        TransitionToBlendedSnapshot(snapshots, weights);
    }
    
    // 游戏状态监听
    void OnGameStateChanged(GameState newState)
    {
        TransitionToSnapshot(newState);
    }
    
    // 暂停游戏时的音频处理
    void OnApplicationPause(bool pauseStatus)
    {
        if (pauseStatus)
        {
            TransitionToSnapshot(GameState.Paused);
        }
        else
        {
            TransitionToSnapshot(GameState.Normal);
        }
    }
}

public enum GameState
{
    Normal,
    Paused,
    Combat,
    Menu
}
```

---

## 3D音频和空间化

### 空间音频算法

#### 1. HRTF和双耳渲染
```csharp
public class SpatialAudioController : MonoBehaviour
{
    [Header("空间音频设置")]
    public bool enableSpatialAudio = true;
    public AudioSpatializerUserData spatializerData;
    
    [Header("HRTF设置")]
    public bool enableHRTF = true;
    public float headRadius = 0.0875f; // 人头半径（米）
    
    [Header("房间模拟")]
    public bool enableRoomSimulation = true;
    public float roomSize = 10f;
    public float wallAbsorption = 0.1f;
    
    private AudioSource audioSource;
    
    void Start()
    {
        audioSource = GetComponent<AudioSource>();
        SetupSpatialAudio();
    }
    
    void SetupSpatialAudio()
    {
        if (audioSource == null)
            return;
        
        // 启用空间化
        audioSource.spatialize = enableSpatialAudio;
        audioSource.spatializePostEffects = false;
        
        // 设置3D音频参数
        audioSource.spatialBlend = 1f; // 完全3D
        audioSource.rolloffMode = AudioRolloffMode.Logarithmic;
        
        // 配置空间化参数
        ConfigureSpatializationParameters();
    }
    
    void ConfigureSpatializationParameters()
    {
        if (spatializerData != null)
        {
            // 设置用户自定义空间化参数
            audioSource.SetSpatializerFloat(0, headRadius);
            audioSource.SetSpatializerFloat(1, roomSize);
            audioSource.SetSpatializerFloat(2, wallAbsorption);
        }
    }
    
    // 计算双耳音频
    void CalculateBinauralAudio(Vector3 soundPosition, Vector3 listenerPosition, 
                              Vector3 listenerForward, Vector3 listenerUp)
    {
        // 计算相对位置
        Vector3 relativePosition = soundPosition - listenerPosition;
        
        // 转换到听者坐标系
        Vector3 listenerRight = Vector3.Cross(listenerForward, listenerUp);
        
        float x = Vector3.Dot(relativePosition, listenerRight);
        float y = Vector3.Dot(relativePosition, listenerUp);
        float z = Vector3.Dot(relativePosition, listenerForward);
        
        // 计算球坐标
        float distance = relativePosition.magnitude;
        float azimuth = Mathf.Atan2(x, z) * Mathf.Rad2Deg;
        float elevation = Mathf.Asin(y / distance) * Mathf.Rad2Deg;
        
        // 应用HRTF
        ApplyHRTF(azimuth, elevation, distance);
    }
    
    void ApplyHRTF(float azimuth, float elevation, float distance)
    {
        // HRTF实现（简化版）
        
        // 计算时间延迟差（ITD）
        float itd = CalculateITD(azimuth);
        
        // 计算强度差（ILD）
        float ild = CalculateILD(azimuth, elevation);
        
        // 应用头部阴影效应
        float headShadow = CalculateHeadShadowEffect(azimuth, elevation);
        
        // 设置左右声道参数
        ApplyBinauralParameters(itd, ild, headShadow);
    }
    
    float CalculateITD(float azimuth)
    {
        // 时间延迟差计算
        float maxDelay = headRadius / 343f; // 声速343m/s
        return maxDelay * Mathf.Sin(azimuth * Mathf.Deg2Rad);
    }
    
    float CalculateILD(float azimuth, float elevation)
    {
        // 强度差计算
        float angle = Mathf.Abs(azimuth);
        return Mathf.Pow(Mathf.Cos(angle * Mathf.Deg2Rad), 2);
    }
    
    float CalculateHeadShadowEffect(float azimuth, float elevation)
    {
        // 头部阴影效应
        float laterality = Mathf.Abs(azimuth) / 90f;
        return Mathf.Lerp(1f, 0.3f, laterality);
    }
    
    void ApplyBinauralParameters(float itd, float ild, float headShadow)
    {
        // 应用双耳参数到AudioSource
        // 这里需要自定义音频处理插件或使用第三方空间音频解决方案
        
        Debug.Log($"ITD: {itd:F4}s, ILD: {ild:F2}, Head Shadow: {headShadow:F2}");
    }
}
```

#### 2. 声学环境模拟
```csharp
public class AcousticEnvironmentSimulator : MonoBehaviour
{
    [Header("房间声学")]
    public Vector3 roomSize = new Vector3(10, 3, 8);
    public float[] wallAbsorption = { 0.1f, 0.1f, 0.1f, 0.1f, 0.1f, 0.1f }; // 6个面
    
    [Header("材质属性")]
    public Material[] roomMaterials = new Material[6];
    
    [Header("反射计算")]
    public int maxReflectionOrder = 3;
    public float minReflectionGain = 0.01f;
    
    private List<ReflectionPath> reflectionPaths;
    
    void Start()
    {
        CalculateRoomAcoustics();
    }
    
    void CalculateRoomAcoustics()
    {
        reflectionPaths = new List<ReflectionPath>();
        
        // 计算所有反射路径
        for (int order = 1; order <= maxReflectionOrder; order++)
        {
            CalculateReflections(order);
        }
        
        // 应用房间脉冲响应
        ApplyRoomImpulseResponse();
    }
    
    void CalculateReflections(int order)
    {
        // 递归计算不同阶次的反射
        Vector3 sourcePos = transform.position;
        Vector3 listenerPos = AudioListener.transform.position;
        
        // 一阶反射：直接从墙面反射
        if (order == 1)
        {
            CalculateFirstOrderReflections(sourcePos, listenerPos);
        }
        else
        {
            // 高阶反射：从之前的反射点继续反射
            CalculateHigherOrderReflections(order, sourcePos, listenerPos);
        }
    }
    
    void CalculateFirstOrderReflections(Vector3 source, Vector3 listener)
    {
        // 6个墙面的反射
        Vector3[] wallNormals = {
            Vector3.right,   // 右墙
            Vector3.left,    // 左墙
            Vector3.up,      // 天花板
            Vector3.down,    // 地板
            Vector3.forward, // 前墙
            Vector3.back     // 后墙
        };
        
        Vector3[] wallPositions = {
            new Vector3(roomSize.x/2, 0, 0),
            new Vector3(-roomSize.x/2, 0, 0),
            new Vector3(0, roomSize.y/2, 0),
            new Vector3(0, -roomSize.y/2, 0),
            new Vector3(0, 0, roomSize.z/2),
            new Vector3(0, 0, -roomSize.z/2)
        };
        
        for (int i = 0; i < 6; i++)
        {
            Vector3 reflectionPoint = CalculateReflectionPoint(source, listener, 
                                                             wallPositions[i], wallNormals[i]);
            
            float distance = Vector3.Distance(source, reflectionPoint) + 
                           Vector3.Distance(reflectionPoint, listener);
            
            float delay = distance / 343f; // 声速
            float gain = CalculateReflectionGain(distance, wallAbsorption[i]);
            
            if (gain > minReflectionGain)
            {
                reflectionPaths.Add(new ReflectionPath
                {
                    delay = delay,
                    gain = gain,
                    reflectionPoint = reflectionPoint,
                    order = 1
                });
            }
        }
    }
    
    Vector3 CalculateReflectionPoint(Vector3 source, Vector3 listener, 
                                   Vector3 wallPos, Vector3 wallNormal)
    {
        // 计算镜像源位置
        Vector3 toWall = wallPos - source;
        float distToWall = Vector3.Dot(toWall, wallNormal);
        Vector3 mirrorSource = source + 2 * distToWall * wallNormal;
        
        // 计算反射点
        Vector3 sourceToListener = listener - mirrorSource;
        float t = Vector3.Dot(wallPos - mirrorSource, wallNormal) / 
                 Vector3.Dot(sourceToListener, wallNormal);
        
        return mirrorSource + t * sourceToListener;
    }
    
    float CalculateReflectionGain(float distance, float absorption)
    {
        // 距离衰减
        float distanceAttenuation = 1f / (distance * distance);
        
        // 材质吸收
        float reflectionCoeff = 1f - absorption;
        
        return distanceAttenuation * reflectionCoeff;
    }
    
    void CalculateHigherOrderReflections(int order, Vector3 source, Vector3 listener)
    {
        // 高阶反射计算（简化实现）
        // 实际实现需要递归追踪反射路径
    }
    
    void ApplyRoomImpulseResponse()
    {
        // 生成房间脉冲响应
        float[] impulseResponse = GenerateImpulseResponse();
        
        // 应用到音频处理链
        ApplyConvolution(impulseResponse);
    }
    
    float[] GenerateImpulseResponse()
    {
        int sampleRate = AudioSettings.outputSampleRate;
        float maxDelay = 0.5f; // 最大延迟时间
        int impulseLength = Mathf.RoundToInt(maxDelay * sampleRate);
        
        float[] impulse = new float[impulseLength];
        
        // 直达声
        impulse[0] = 1f;
        
        // 添加反射
        foreach (ReflectionPath reflection in reflectionPaths)
        {
            int sampleIndex = Mathf.RoundToInt(reflection.delay * sampleRate);
            if (sampleIndex < impulseLength)
            {
                impulse[sampleIndex] += reflection.gain;
            }
        }
        
        return impulse;
    }
    
    void ApplyConvolution(float[] impulseResponse)
    {
        // 将脉冲响应应用到音频处理
        // 这需要自定义音频滤波器或使用AudioMixer的回响效果
        
        Debug.Log($"Generated impulse response with {impulseResponse.Length} samples");
        Debug.Log($"Found {reflectionPaths.Count} reflection paths");
    }
    
    void OnDrawGizmos()
    {
        // 绘制房间和反射路径
        Gizmos.color = Color.white;
        Gizmos.DrawWireCube(transform.position, roomSize);
        
        if (reflectionPaths != null)
        {
            Gizmos.color = Color.yellow;
            foreach (ReflectionPath path in reflectionPaths)
            {
                Gizmos.DrawSphere(path.reflectionPoint, 0.1f);
            }
        }
    }
}

[System.Serializable]
public class ReflectionPath
{
    public float delay;
    public float gain;
    public Vector3 reflectionPoint;
    public int order;
}
```

---

## 音频优化策略

### 1. 性能优化
```csharp
public class AudioPerformanceOptimizer : MonoBehaviour
{
    [Header("音频池设置")]
    public int maxAudioSources = 32;
    public int preloadedSources = 16;
    
    [Header("优化设置")]
    public bool enableAudioLOD = true;
    public float audioLODDistance = 50f;
    public int maxSimultaneousSounds = 16;
    
    private ObjectPool<AudioSource> audioSourcePool;
    private List<PlayingAudioInfo> playingAudios;
    private Camera playerCamera;
    
    void Start()
    {
        InitializeAudioPool();
        InitializeAudioLOD();
        
        playerCamera = Camera.main;
        playingAudios = new List<PlayingAudioInfo>();
    }
    
    void InitializeAudioPool()
    {
        // 创建AudioSource对象池
        audioSourcePool = new ObjectPool<AudioSource>(
            createFunc: CreatePooledAudioSource,
            actionOnGet: OnGetAudioSource,
            actionOnRelease: OnReleaseAudioSource,
            actionOnDestroy: OnDestroyAudioSource,
            collectionCheck: false,
            defaultCapacity: preloadedSources,
            maxSize: maxAudioSources
        );
        
        // 预加载AudioSource
        for (int i = 0; i < preloadedSources; i++)
        {
            AudioSource source = audioSourcePool.Get();
            audioSourcePool.Release(source);
        }
    }
    
    AudioSource CreatePooledAudioSource()
    {
        GameObject audioObject = new GameObject("PooledAudioSource");
        audioObject.transform.SetParent(transform);
        
        AudioSource source = audioObject.AddComponent<AudioSource>();
        source.playOnAwake = false;
        source.spatialBlend = 1f; // 3D音频
        
        return source;
    }
    
    void OnGetAudioSource(AudioSource source)
    {
        source.gameObject.SetActive(true);
    }
    
    void OnReleaseAudioSource(AudioSource source)
    {
        source.Stop();
        source.clip = null;
        source.gameObject.SetActive(false);
        
        // 移除播放信息
        playingAudios.RemoveAll(info => info.audioSource == source);
    }
    
    void OnDestroyAudioSource(AudioSource source)
    {
        if (source != null && source.gameObject != null)
        {
            Destroy(source.gameObject);
        }
    }
    
    // 优化的音频播放
    public AudioSource PlayAudioOptimized(AudioClip clip, Vector3 position, 
                                        float volume = 1f, float pitch = 1f, 
                                        bool loop = false)
    {
        // 检查是否超过最大同时播放数
        if (playingAudios.Count >= maxSimultaneousSounds)
        {
            // 停止最远或最老的音频
            StopLeastImportantAudio();
        }
        
        // 距离剔除
        if (enableAudioLOD && playerCamera != null)
        {
            float distance = Vector3.Distance(position, playerCamera.transform.position);
            if (distance > audioLODDistance)
            {
                return null; // 距离太远，不播放
            }
        }
        
        // 从对象池获取AudioSource
        AudioSource audioSource = audioSourcePool.Get();
        
        // 设置音频参数
        audioSource.clip = clip;
        audioSource.volume = volume;
        audioSource.pitch = pitch;
        audioSource.loop = loop;
        audioSource.transform.position = position;
        
        // 根据距离调整音质
        ApplyAudioLOD(audioSource, position);
        
        // 播放音频
        audioSource.Play();
        
        // 记录播放信息
        playingAudios.Add(new PlayingAudioInfo
        {
            audioSource = audioSource,
            startTime = Time.time,
            priority = CalculateAudioPriority(clip, position)
        });
        
        // 设置自动回收
        if (!loop)
        {
            StartCoroutine(AutoReleaseAudioSource(audioSource, clip.length));
        }
        
        return audioSource;
    }
    
    void StopLeastImportantAudio()
    {
        if (playingAudios.Count == 0)
            return;
        
        // 按优先级排序，停止优先级最低的
        playingAudios.Sort((a, b) => a.priority.CompareTo(b.priority));
        
        PlayingAudioInfo leastImportant = playingAudios[0];
        audioSourcePool.Release(leastImportant.audioSource);
    }
    
    void ApplyAudioLOD(AudioSource audioSource, Vector3 position)
    {
        if (!enableAudioLOD || playerCamera == null)
            return;
        
        float distance = Vector3.Distance(position, playerCamera.transform.position);
        float lodFactor = Mathf.Clamp01(1f - (distance / audioLODDistance));
        
        // 根据距离调整音质
        if (lodFactor < 0.5f)
        {
            // 远距离：降低采样率、应用低通滤波
            ApplyLowQualitySettings(audioSource);
        }
        else if (lodFactor < 0.8f)
        {
            // 中距离：中等质量
            ApplyMediumQualitySettings(audioSource);
        }
        else
        {
            // 近距离：高质量
            ApplyHighQualitySettings(audioSource);
        }
    }
    
    void ApplyLowQualitySettings(AudioSource audioSource)
    {
        // 可以添加低通滤波器组件
        AudioLowPassFilter lowPass = audioSource.GetComponent<AudioLowPassFilter>();
        if (lowPass == null)
            lowPass = audioSource.gameObject.AddComponent<AudioLowPassFilter>();
        
        lowPass.cutoffFrequency = 3000f;
    }
    
    void ApplyMediumQualitySettings(AudioSource audioSource)
    {
        AudioLowPassFilter lowPass = audioSource.GetComponent<AudioLowPassFilter>();
        if (lowPass == null)
            lowPass = audioSource.gameObject.AddComponent<AudioLowPassFilter>();
        
        lowPass.cutoffFrequency = 8000f;
    }
    
    void ApplyHighQualitySettings(AudioSource audioSource)
    {
        // 移除低通滤波器
        AudioLowPassFilter lowPass = audioSource.GetComponent<AudioLowPassFilter>();
        if (lowPass != null)
        {
            Destroy(lowPass);
        }
    }
    
    float CalculateAudioPriority(AudioClip clip, Vector3 position)
    {
        float distance = playerCamera ? 
            Vector3.Distance(position, playerCamera.transform.position) : 0f;
        
        // 距离越近优先级越高，重要音效优先级更高
        float distancePriority = 1f / (1f + distance);
        float clipPriority = GetClipPriority(clip);
        
        return distancePriority * clipPriority;
    }
    
    float GetClipPriority(AudioClip clip)
    {
        // 根据音频类型设置优先级
        if (clip.name.Contains("Voice") || clip.name.Contains("Dialog"))
            return 3f; // 语音最高优先级
        
        if (clip.name.Contains("Music"))
            return 2f; // 音乐中等优先级
        
        return 1f; // 音效低优先级
    }
    
    IEnumerator AutoReleaseAudioSource(AudioSource audioSource, float delay)
    {
        yield return new WaitForSeconds(delay + 0.1f); // 添加小缓冲
        
        if (audioSource != null && !audioSource.isPlaying)
        {
            audioSourcePool.Release(audioSource);
        }
    }
    
    void Update()
    {
        // 清理已停止播放的音频
        CleanupFinishedAudios();
    }
    
    void CleanupFinishedAudios()
    {
        for (int i = playingAudios.Count - 1; i >= 0; i--)
        {
            PlayingAudioInfo info = playingAudios[i];
            
            if (info.audioSource == null || !info.audioSource.isPlaying)
            {
                if (info.audioSource != null)
                {
                    audioSourcePool.Release(info.audioSource);
                }
                playingAudios.RemoveAt(i);
            }
        }
    }
}

[System.Serializable]
public class PlayingAudioInfo
{
    public AudioSource audioSource;
    public float startTime;
    public float priority;
}
```

### 2. 内存优化
```csharp
public class AudioMemoryOptimizer : MonoBehaviour
{
    [Header("内存管理")]
    public float audioCleanupInterval = 30f;
    public int maxCachedClips = 50;
    
    private Dictionary<string, AudioClip> audioClipCache;
    private Dictionary<string, float> lastAccessTime;
    
    void Start()
    {
        audioClipCache = new Dictionary<string, AudioClip>();
        lastAccessTime = new Dictionary<string, float>();
        
        // 定期清理未使用的音频
        InvokeRepeating(nameof(CleanupUnusedAudioClips), audioCleanupInterval, audioCleanupInterval);
    }
    
    // 智能音频加载
    public AudioClip LoadAudioClipOptimized(string path, AudioClipLoadType loadType = AudioClipLoadType.DecompressOnLoad)
    {
        // 检查缓存
        if (audioClipCache.ContainsKey(path))
        {
            lastAccessTime[path] = Time.time;
            return audioClipCache[path];
        }
        
        // 加载新音频
        AudioClip clip = Resources.Load<AudioClip>(path);
        
        if (clip != null)
        {
            // 根据文件大小和类型选择加载策略
            OptimizeAudioClipLoading(clip, loadType);
            
            // 添加到缓存
            if (audioClipCache.Count < maxCachedClips)
            {
                audioClipCache[path] = clip;
                lastAccessTime[path] = Time.time;
            }
        }
        
        return clip;
    }
    
    void OptimizeAudioClipLoading(AudioClip clip, AudioClipLoadType loadType)
    {
        // 根据音频长度和用途优化加载策略
        float duration = clip.length;
        
        if (duration < 2f)
        {
            // 短音效：解压到内存
            clip.LoadAudioData();
        }
        else if (duration < 10f)
        {
            // 中等长度：压缩在内存中
            if (loadType == AudioClipLoadType.CompressedInMemory)
            {
                // 保持压缩状态
            }
        }
        else
        {
            // 长音频：流式播放
            if (loadType == AudioClipLoadType.Streaming)
            {
                clip.UnloadAudioData(); // 确保不占用内存
            }
        }
    }
    
    void CleanupUnusedAudioClips()
    {
        List<string> keysToRemove = new List<string>();
        
        foreach (var kvp in lastAccessTime)
        {
            string path = kvp.Key;
            float lastAccess = kvp.Value;
            
            // 如果超过清理间隔时间未使用
            if (Time.time - lastAccess > audioCleanupInterval)
            {
                keysToRemove.Add(path);
            }
        }
        
        // 移除未使用的音频
        foreach (string key in keysToRemove)
        {
            if (audioClipCache.ContainsKey(key))
            {
                AudioClip clip = audioClipCache[key];
                if (clip != null)
                {
                    clip.UnloadAudioData();
                    Resources.UnloadAsset(clip);
                }
                
                audioClipCache.Remove(key);
                lastAccessTime.Remove(key);
            }
        }
        
        if (keysToRemove.Count > 0)
        {
            Debug.Log($"Cleaned up {keysToRemove.Count} unused audio clips");
            
            // 强制垃圾回收
            System.GC.Collect();
            Resources.UnloadUnusedAssets();
        }
    }
    
    // 预加载重要音频
    public void PreloadEssentialAudio(string[] audioPaths)
    {
        foreach (string path in audioPaths)
        {
            LoadAudioClipOptimized(path, AudioClipLoadType.DecompressOnLoad);
        }
    }
    
    // 获取音频内存使用情况
    public void LogAudioMemoryUsage()
    {
        long totalMemory = 0;
        int loadedClips = 0;
        
        foreach (var kvp in audioClipCache)
        {
            AudioClip clip = kvp.Value;
            if (clip != null && clip.loadState == AudioDataLoadState.Loaded)
            {
                // 估算内存使用（采样数 * 声道数 * 每样本字节数）
                long clipMemory = clip.samples * clip.channels * sizeof(float);
                totalMemory += clipMemory;
                loadedClips++;
            }
        }
        
        Debug.Log($"Audio Memory Usage: {totalMemory / (1024 * 1024)}MB, Loaded Clips: {loadedClips}");
    }
    
    void OnApplicationPause(bool pauseStatus)
    {
        if (pauseStatus)
        {
            // 应用暂停时卸载非关键音频
            UnloadNonEssentialAudio();
        }
    }
    
    void UnloadNonEssentialAudio()
    {
        foreach (var kvp in audioClipCache)
        {
            AudioClip clip = kvp.Value;
            if (clip != null && !IsEssentialAudio(kvp.Key))
            {
                clip.UnloadAudioData();
            }
        }
    }
    
    bool IsEssentialAudio(string path)
    {
        // 判断是否为关键音频（UI音效、重要游戏音效等）
        return path.Contains("UI") || path.Contains("Essential") || path.Contains("Critical");
    }
}
```

---

## 常见面试问题

### 1. **Q: AudioSource的不同播放模式有什么区别？**
```
A: 播放模式对比：
1. Play()：
   - 从头开始播放
   - 会停止当前播放的音频
   - 适合单次播放音效

2. PlayOneShot()：
   - 一次性播放，不影响当前音频
   - 无法停止或控制
   - 适合重叠音效（如枪声、脚步声）

3. PlayDelayed()：
   - 延迟指定时间后播放
   - 基于游戏时间
   - 适合同步音效

4. PlayScheduled()：
   - 在音频时间轴上的特定时间播放
   - 基于DSP时间，精确同步
   - 适合音乐节拍同步

使用建议：
- UI音效 → PlayOneShot()
- 背景音乐 → Play()
- 音乐同步 → PlayScheduled()
```

### 2. **Q: 3D音频的空间化算法原理？**
```
A: 空间化技术：
1. 双耳渲染（Binaural）：
   - ITD（时间延迟差）：左右耳到达时间差
   - ILD（强度差）：左右耳音量差
   - HRTF（头部相关传输函数）：头部和耳朵的声学特性

2. 距离衰减：
   // 对数衰减（最常用）
   volume = minDistance / distance
   
   // 线性衰减
   volume = 1 - (distance - minDistance) / (maxDistance - minDistance)

3. 多普勒效应：
   frequency = originalFreq * (speedOfSound + receiverVelocity) / 
               (speedOfSound + sourceVelocity)

4. 环境声学：
   - 早期反射：墙面反射
   - 后期回响：房间混响
   - 遮挡/阻挡：障碍物影响
```

### 3. **Q: AudioMixer的优势和使用场景？**
```
A: AudioMixer优势：
1. 实时混音控制：
   - 动态调整音量、音效
   - 音频分组管理
   - 平滑参数过渡

2. 专业音频处理：
   - 内置效果器（EQ、压缩、回响等）
   - 实时参数控制
   - 音频快照系统

3. 性能优化：
   - GPU加速音频处理
   - 批量音频处理
   - 减少CPU开销

使用场景：
// 游戏状态音频切换
audioMixer.FindSnapshot("Combat").TransitionTo(1f);

// 动态音效控制
audioMixer.SetFloat("LowpassCutoff", 1000f); // 水下效果

// 音量分组管理
audioMixer.SetFloat("MasterVolume", volumeSlider.value);
```

### 4. **Q: 音频内存优化的策略？**
```
A: 优化策略：
1. 加载方式选择：
   - 短音效（<2s）：DecompressOnLoad
   - 中等音频（2-10s）：CompressedInMemory
   - 长音频（>10s）：Streaming

2. 压缩格式：
   - 移动端：Vorbis（平衡质量和大小）
   - PC：PCM（最佳质量）或Vorbis
   - 语音：ADPCM（高压缩比）

3. 内存管理：
   // 对象池
   AudioSource source = audioPool.Get();
   
   // 及时卸载
   audioClip.UnloadAudioData();
   
   // 缓存管理
   if (lastUsedTime > threshold) {
       UnloadAudioClip(clip);
   }

4. 质量设置：
   - 采样率：44.1kHz（音乐）、22kHz（音效）
   - 位深度：16bit（一般用途）
   - 立体声vs单声道：根据需要选择
```

### 5. **Q: 如何实现音频的无缝循环？**
```
A: 无缝循环实现：
1. 音频制作要求：
   - 精确的循环点设置
   - 波形首尾匹配
   - 避免爆音（Pop）

2. 代码实现：
   public class SeamlessAudioLoop : MonoBehaviour
   {
       public AudioSource audioSource;
       public AudioClip loopClip;
       public float loopStartTime = 0f;
       public float loopEndTime = 10f;
       
       void Update()
       {
           if (audioSource.time >= loopEndTime)
           {
               audioSource.time = loopStartTime;
           }
       }
   }

3. 高级技术：
   - 交叉淡化：两个AudioSource交替播放
   - DSP精确计时：使用AudioSettings.dspTime
   - 预计算循环点：分析音频波形

4. 性能考虑：
   - 避免频繁的time设置
   - 使用音频回调优化
   - 考虑音频延迟补偿
```

---

*这份文档全面讲解了Unity音频系统的各个方面，从基础组件到高级空间化技术，适合深度技术面试准备。*